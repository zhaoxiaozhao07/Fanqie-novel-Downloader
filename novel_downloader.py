# -*- coding: utf-8 -*-
"""
ç•ªèŒ„å°è¯´ä¸‹è½½å™¨æ ¸å¿ƒæ¨¡å— - å¯¹æ¥å®˜æ–¹API https://fq.shusan.cn/docs
"""

import time
import requests
import re
import os
import json
import urllib3
import threading
import signal
import sys
import inspect
from concurrent.futures import ThreadPoolExecutor, as_completed
import asyncio
from tqdm import tqdm
from typing import Optional, Dict, List
from ebooklib import epub
from config import CONFIG, print_lock, get_headers
import aiohttp
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from watermark import apply_watermark_to_chapter
from locales import t

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
requests.packages.urllib3.disable_warnings()

# ===================== å®˜æ–¹APIç®¡ç†å™¨ =====================

class APIManager:
    """ç•ªèŒ„å°è¯´å®˜æ–¹APIç»Ÿä¸€ç®¡ç†å™¨ - https://fq.shusan.cn/docs
    æ”¯æŒåŒæ­¥å’Œå¼‚æ­¥ä¸¤ç§è°ƒç”¨æ–¹å¼
    """
    
    def __init__(self):
        # ä» api_sources è·å–ç¬¬ä¸€ä¸ªå¯ç”¨çš„ base_urlï¼ˆapi_base_url å·²åºŸå¼ƒï¼‰
        api_sources = CONFIG.get("api_sources", [])
        if api_sources and isinstance(api_sources, list) and len(api_sources) > 0:
            self.base_url = api_sources[0].get("base_url", "")
        else:
            self.base_url = CONFIG.get("api_base_url", "")
        self.endpoints = CONFIG["endpoints"]
        self._tls = threading.local()
        self._async_session: Optional[aiohttp.ClientSession] = None
        self.semaphore = None
        self.last_request_time = 0
        self.request_lock = asyncio.Lock()

    def _get_session(self) -> requests.Session:
        """è·å–åŒæ­¥HTTPä¼šè¯"""
        sess = getattr(self._tls, 'session', None)
        if sess is None:
            sess = requests.Session()
            retries = Retry(
                total=CONFIG.get("max_retries", 3),
                backoff_factor=0.3,
                status_forcelist=(429, 500, 502, 503, 504),
                allowed_methods=("GET", "POST"),
                raise_on_status=False,
            )
            pool_size = CONFIG.get("connection_pool_size", 10)
            adapter = HTTPAdapter(
                pool_connections=pool_size, 
                pool_maxsize=pool_size, 
                max_retries=retries,
                pool_block=False
            )
            sess.mount('http://', adapter)
            sess.mount('https://', adapter)
            sess.headers.update({'Connection': 'keep-alive'})
            self._tls.session = sess
        return sess

    async def _get_async_session(self) -> aiohttp.ClientSession:
        """è·å–å¼‚æ­¥HTTPä¼šè¯"""
        if self._async_session is None or self._async_session.closed:
            timeout = aiohttp.ClientTimeout(total=CONFIG["request_timeout"], connect=5, sock_read=15)
            connector = aiohttp.TCPConnector(
                limit=CONFIG.get("connection_pool_size", 10),
                limit_per_host=CONFIG.get("connection_pool_size", 10),
                ttl_dns_cache=300,
                enable_cleanup_closed=True,
                force_close=False,
                keepalive_timeout=30
            )
            self._async_session = aiohttp.ClientSession(
                headers=get_headers(), 
                timeout=timeout, 
                connector=connector,
                trust_env=True
            )
            self.semaphore = asyncio.Semaphore(CONFIG.get("max_workers", 5))
        return self._async_session

    async def close_async(self):
        """å…³é—­å¼‚æ­¥ä¼šè¯"""
        if self._async_session:
            await self._async_session.close()
    
    def search_books(self, keyword: str, offset: int = 0) -> Optional[Dict]:
        """æœç´¢ä¹¦ç±"""
        try:
            url = f"{self.base_url}{self.endpoints['search']}"
            params = {"key": keyword, "tab_type": "3", "offset": str(offset)}
            response = self._get_session().get(url, params=params, headers=get_headers(), timeout=CONFIG["request_timeout"])
            
            if response.status_code == 200:
                data = response.json()
                if data.get("code") == 200:
                    return data
            return None
        except Exception as e:
            with print_lock:
                print(t("dl_search_error", str(e)))
            return None
    
    def get_book_detail(self, book_id: str) -> Optional[Dict]:
        """è·å–ä¹¦ç±è¯¦æƒ…ï¼Œè¿”å› dict æˆ– Noneï¼Œå¦‚æœä¹¦ç±ä¸‹æ¶ä¼šè¿”å› {'_error': 'BOOK_REMOVE'}"""
        try:
            url = f"{self.base_url}{self.endpoints['detail']}"
            params = {"book_id": book_id}
            response = self._get_session().get(url, params=params, headers=get_headers(), timeout=CONFIG["request_timeout"])
            
            if response.status_code == 200:
                data = response.json()
                if data.get("code") == 200 and "data" in data:
                    level1_data = data["data"]
                    # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚ä¹¦ç±ä¸‹æ¶ï¼‰
                    if isinstance(level1_data, dict):
                        inner_msg = level1_data.get("message", "")
                        inner_code = level1_data.get("code")
                        if inner_msg == "BOOK_REMOVE" or inner_code == 101109:
                            return {"_error": "BOOK_REMOVE", "_message": "ä¹¦ç±å·²ä¸‹æ¶"}
                        if "data" in level1_data:
                            inner_data = level1_data["data"]
                            # å¦‚æœå†…å±‚ data æ˜¯ç©ºçš„ï¼Œä¹Ÿå¯èƒ½æ˜¯ä¸‹æ¶
                            if isinstance(inner_data, dict) and not inner_data and inner_msg:
                                return {"_error": inner_msg, "_message": inner_msg}
                            return inner_data
                    return level1_data
            return None
        except Exception as e:
            with print_lock:
                print(t("dl_detail_error", str(e)))
            return None
    
    def get_directory(self, book_id: str) -> Optional[List[Dict]]:
        """è·å–ç®€åŒ–ç›®å½•ï¼ˆæ›´å¿«ï¼Œæ ‡é¢˜ä¸æ•´æœ¬ä¸‹è½½å†…å®¹ä¸€è‡´ï¼‰"""
        try:
            endpoint = self.endpoints.get('directory')
            if not endpoint:
                return None
            
            url = f"{self.base_url}{endpoint}"
            params = {"book_id": book_id}
            response = self._get_session().get(url, params=params, headers=get_headers(), timeout=CONFIG["request_timeout"])
            
            if response.status_code == 200:
                data = response.json()
                if data.get("code") == 200 and "data" in data:
                    lists = data["data"].get("lists", [])
                    if lists:
                        return lists
            return None
        except Exception:
            return None
    
    def get_chapter_list(self, book_id: str) -> Optional[List[Dict]]:
        """è·å–ç« èŠ‚åˆ—è¡¨"""
        try:
            with print_lock:
                print(t("dl_chapter_list_start", book_id))
                
            url = f"{self.base_url}{self.endpoints['book']}"
            params = {"book_id": book_id}
            response = self._get_session().get(url, params=params, headers=get_headers(), timeout=CONFIG["request_timeout"])
            
            with print_lock:
                print(t("dl_chapter_list_resp", response.status_code))
            
            if response.status_code == 200:
                data = response.json()
                if data.get("code") == 200 and "data" in data:
                    level1_data = data["data"]
                    if isinstance(level1_data, dict) and "data" in level1_data:
                        return level1_data["data"]
                    return level1_data
            return None
        except Exception as e:
            with print_lock:
                print(t("dl_chapter_list_error", str(e)))
            return None
    
    def get_chapter_content(self, item_id: str) -> Optional[Dict]:
        """è·å–ç« èŠ‚å†…å®¹(åŒæ­¥)"""
        try:
            url = f"{self.base_url}{self.endpoints['content']}"
            params = {"tab": "å°è¯´", "item_id": item_id}
            response = self._get_session().get(url, params=params, headers=get_headers(), timeout=CONFIG["request_timeout"])
            
            if response.status_code == 200:
                data = response.json()
                if data.get("code") == 200 and "data" in data:
                    return data["data"]
            return None
        except Exception as e:
            with print_lock:
                print(t("dl_content_error", str(e)))
            return None

    async def get_chapter_content_async(self, item_id: str) -> Optional[Dict]:
        """è·å–ç« èŠ‚å†…å®¹(å¼‚æ­¥)"""
        max_retries = CONFIG.get("max_retries", 3)
        
        async with self.semaphore:
            async with self.request_lock:
                current_time = time.time()
                time_since_last = current_time - self.last_request_time
                if time_since_last < CONFIG.get("download_delay", 0.5):
                    await asyncio.sleep(CONFIG.get("download_delay", 0.5) - time_since_last)
                self.last_request_time = time.time()
            
            session = await self._get_async_session()
            url = f"{self.base_url}{self.endpoints['content']}"
            params = {"tab": "å°è¯´", "item_id": item_id}
            
            for attempt in range(max_retries):
                try:
                    async with session.get(url, params=params) as response:
                        if response.status == 200:
                            data = await response.json()
                            if data.get("code") == 200 and "data" in data:
                                return data["data"]
                        elif response.status == 429:
                            await asyncio.sleep(min(2 ** attempt, 10))
                            continue
                        return None
                except asyncio.TimeoutError:
                    if attempt < max_retries - 1:
                        await asyncio.sleep(CONFIG.get("retry_delay", 2) * (attempt + 1))
                        continue
                    return None
                except Exception:
                    if attempt < max_retries - 1:
                        await asyncio.sleep(0.3)
                        continue
                    return None
            
            return None

    def get_full_content(self, book_id: str) -> Optional[str]:
        """è·å–æ•´æœ¬å°è¯´å†…å®¹(çº¯æ–‡æœ¬)"""
        try:
            # ä½¿ç”¨ /api/content?tab=ä¸‹è½½ ç«¯ç‚¹è¿›è¡Œæ•´ä¹¦ä¸‹è½½
            # æ³¨æ„: /api/raw_full éœ€è¦ item_idï¼ˆç« èŠ‚IDï¼‰ï¼Œä¸é€‚ç”¨äºæ•´ä¹¦ä¸‹è½½
            endpoint = self.endpoints.get('content')
            if not endpoint:
                return None
                
            url = f"{self.base_url}{endpoint}"
            params = {"tab": "ä¸‹è½½", "book_id": book_id}
            
            response = self._get_session().get(url, params=params, headers=get_headers(), timeout=60, stream=True)
            if response.status_code != 200:
                return None
            
            raw_content = response.content
            content_type = (response.headers.get('content-type') or '').lower()
            
            def _extract_text(payload):
                if isinstance(payload, str):
                    return payload
                if isinstance(payload, dict):
                    # å…ˆçœ‹åµŒå¥— dataï¼Œå†çœ‹å¸¸è§æ–‡æœ¬å­—æ®µ
                    nested = payload.get('data')
                    if isinstance(nested, str):
                        return nested
                    if isinstance(nested, dict):
                        for key in ("content", "text", "raw", "raw_text", "full_text"):
                            val = nested.get(key)
                            if isinstance(val, str):
                                return val
                    for key in ("content", "text", "raw", "raw_text", "full_text"):
                        val = payload.get(key)
                        if isinstance(val, str):
                            return val
                return None
            
            # ä¼˜å…ˆè§£æ JSON è¿”å›ï¼ˆæ–°æ¥å£å¯èƒ½è¿”å› {code,data:{content:...}}ï¼‰
            is_json_like = 'application/json' in content_type or raw_content[:1] in (b'{', b'[')
            if is_json_like:
                try:
                    data = json.loads(raw_content.decode('utf-8', errors='ignore'))
                except Exception:
                    data = None
                text_from_json = _extract_text(data) if data is not None else None
                if text_from_json:
                    return text_from_json
            
            # å›é€€åˆ°çº¯æ–‡æœ¬è§£ç 
            if not response.encoding:
                response.encoding = response.apparent_encoding or 'utf-8'
            return raw_content.decode(response.encoding or 'utf-8', errors='replace')
        except Exception as e:
            with print_lock:
                print(t("dl_full_content_error", str(e)))
            return None

def _normalize_title(title: str) -> str:
    """æ ‡å‡†åŒ–ç« èŠ‚æ ‡é¢˜ï¼Œç”¨äºæ¨¡ç³ŠåŒ¹é…"""
    # ç§»é™¤ç©ºæ ¼
    s = re.sub(r'\s+', '', title)
    # ç»Ÿä¸€æ ‡ç‚¹ï¼šä¸­æ–‡é€—å·ã€é¡¿å·ã€ç‚¹å·ç»Ÿä¸€
    s = re.sub(r'[,ï¼Œã€ï¼.Â·]', '', s)
    # é˜¿æ‹‰ä¼¯æ•°å­—è½¬ä¸­æ–‡æ•°å­—çš„æ˜ å°„ï¼ˆç”¨äºæ¯”è¾ƒï¼‰
    return s.lower()


def _extract_title_core(title: str) -> str:
    """æå–æ ‡é¢˜æ ¸å¿ƒéƒ¨åˆ†ï¼ˆå»æ‰ç« èŠ‚å·å‰ç¼€ï¼‰"""
    # ç§»é™¤ "ç¬¬xç« "ã€"æ•°å­—ã€"ã€"æ•°å­—." ç­‰å‰ç¼€
    s = re.sub(r'^(ç¬¬[0-9ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒ]+ç« [ã€,ï¼Œ\s]*)', '', title)
    s = re.sub(r'^(\d+[ã€,ï¼Œ.\s]+)', '', s)
    return s.strip()


def parse_novel_text_with_catalog(text: str, catalog: List[Dict]) -> List[Dict]:
    """ä½¿ç”¨ç›®å½•æ¥å£çš„ç« èŠ‚æ ‡é¢˜æ¥åˆ†å‰²æ•´æœ¬å°è¯´å†…å®¹
    
    Args:
        text: æ•´æœ¬å°è¯´çš„çº¯æ–‡æœ¬å†…å®¹
        catalog: ç›®å½•æ¥å£è¿”å›çš„ç« èŠ‚åˆ—è¡¨ [{'title': '...', 'id': '...', 'index': ...}, ...]
    
    Returns:
        å¸¦å†…å®¹çš„ç« èŠ‚åˆ—è¡¨ [{'title': '...', 'id': '...', 'index': ..., 'content': '...'}, ...]
    """
    if not catalog:
        return []
    
    def escape_for_regex(s: str) -> str:
        return re.escape(s)
    
    def find_title_in_text(title: str, search_text: str, start_offset: int = 0) -> Optional[tuple]:
        """åœ¨æ–‡æœ¬ä¸­æŸ¥æ‰¾æ ‡é¢˜ï¼Œè¿”å› (match_start, match_end) æˆ– None"""
        # 1. ç²¾ç¡®åŒ¹é…
        pattern = re.compile(r'^[ \t]*' + escape_for_regex(title) + r'[ \t]*$', re.MULTILINE)
        match = pattern.search(search_text)
        if match:
            return (start_offset + match.start(), start_offset + match.end())
        
        # 2. æ¨¡ç³ŠåŒ¹é…ï¼šæå–æ ‡é¢˜æ ¸å¿ƒéƒ¨åˆ†
        title_core = _extract_title_core(title)
        if title_core and len(title_core) >= 2:
            # åŒ¹é…åŒ…å«æ ¸å¿ƒæ ‡é¢˜çš„è¡Œ
            pattern = re.compile(r'^[^\n]*' + escape_for_regex(title_core) + r'[^\n]*$', re.MULTILINE)
            match = pattern.search(search_text)
            if match:
                return (start_offset + match.start(), start_offset + match.end())
        
        return None
    
    # æŸ¥æ‰¾æ¯ä¸ªç« èŠ‚æ ‡é¢˜åœ¨æ–‡æœ¬ä¸­çš„ä½ç½®
    chapter_positions = []
    for ch in catalog:
        title = ch['title']
        result = find_title_in_text(title, text)
        if result:
            chapter_positions.append({
                'title': title,
                'id': ch.get('id', ''),
                'index': ch['index'],
                'line_start': result[0],  # æ ‡é¢˜è¡Œå¼€å§‹ä½ç½®
                'start': result[1]        # å†…å®¹å¼€å§‹ä½ç½®ï¼ˆæ ‡é¢˜è¡Œä¹‹åï¼‰
            })
    
    if not chapter_positions:
        return []
    
    # æŒ‰ä½ç½®æ’åº
    chapter_positions.sort(key=lambda x: x['line_start'])
    
    # æå–æ¯ç« å†…å®¹
    chapters = []
    for i, pos in enumerate(chapter_positions):
        if i + 1 < len(chapter_positions):
            end = chapter_positions[i + 1]['line_start']
        else:
            end = len(text)
        
        content = text[pos['start']:end].strip()
        chapters.append({
            'title': pos['title'],
            'id': pos['id'],
            'index': pos['index'],
            'content': content
        })
    
    # æŒ‰åŸå§‹ç›®å½•é¡ºåºé‡æ–°æ’åº
    chapters.sort(key=lambda x: x['index'])
    
    return chapters


def parse_novel_text(text: str) -> List[Dict]:
    """è§£ææ•´æœ¬å°è¯´æ–‡æœ¬ï¼Œåˆ†ç¦»ç« èŠ‚ï¼ˆæ— ç›®å½•æ—¶çš„é™çº§æ–¹æ¡ˆï¼‰"""
    lines = text.splitlines()
    chapters = []
    
    current_chapter = None
    current_content = []
    
    # åŒ¹é…å¸¸è§ç« èŠ‚æ ¼å¼
    chapter_pattern = re.compile(
        r'^\s*('
        r'ç¬¬[0-9ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒ]+ç« '  # ç¬¬xç« 
        r'|[0-9]+[\.ã€,ï¼Œ]\s*\S'                # 1ã€æ ‡é¢˜ 1.æ ‡é¢˜
        r')\s*.*',
        re.UNICODE
    )
    
    for line in lines:
        match = chapter_pattern.match(line)
        if match:
            if current_chapter:
                current_chapter['content'] = '\n'.join(current_content)
                chapters.append(current_chapter)
            
            title = line.strip()
            current_chapter = {
                'title': title,
                'id': str(len(chapters)),
                'index': len(chapters)
            }
            current_content = []
        else:
            if current_chapter:
                current_content.append(line)
    
    if current_chapter:
        current_chapter['content'] = '\n'.join(current_content)
        chapters.append(current_chapter)
    
    return chapters


# å…¨å±€APIç®¡ç†å™¨å®ä¾‹
api_manager = None

def get_api_manager():
    """è·å–APIç®¡ç†å™¨å®ä¾‹"""
    global api_manager
    if api_manager is None:
        api_manager = APIManager()
    return api_manager


# ===================== è¾…åŠ©å‡½æ•° =====================

def process_chapter_content(content):
    """å¤„ç†ç« èŠ‚å†…å®¹"""
    if not content:
        return ""
    
    # å°†bræ ‡ç­¾å’Œpæ ‡ç­¾æ›¿æ¢ä¸ºæ¢è¡Œç¬¦
    content = re.sub(r'<br\s*/?>\s*', '\n', content)
    content = re.sub(r'<p[^>]*>\s*', '\n', content)
    content = re.sub(r'</p>\s*', '\n', content)
    
    # ç§»é™¤å…¶ä»–HTMLæ ‡ç­¾
    content = re.sub(r'<[^>]+>', '', content)
    
    # æ¸…ç†ç©ºç™½å­—ç¬¦
    content = re.sub(r'[ \t]+', ' ', content)  # å¤šä¸ªç©ºæ ¼æˆ–åˆ¶è¡¨ç¬¦æ›¿æ¢ä¸ºå•ä¸ªç©ºæ ¼
    content = re.sub(r'\n[ \t]+', '\n', content)  # è¡Œé¦–ç©ºç™½
    content = re.sub(r'[ \t]+\n', '\n', content)  # è¡Œå°¾ç©ºç™½
    
    # å°†å¤šä¸ªè¿ç»­æ¢è¡Œç¬¦è§„èŒƒåŒ–ä¸ºåŒæ¢è¡Œï¼ˆæ®µè½åˆ†éš”ï¼‰
    content = re.sub(r'\n{3,}', '\n\n', content)
    
    # å¤„ç†æ®µè½ï¼šç¡®ä¿æ¯ä¸ªéç©ºè¡Œéƒ½æ˜¯ä¸€ä¸ªæ®µè½
    lines = content.split('\n')
    paragraphs = []
    for line in lines:
        line = line.strip()
        if line:  # éç©ºè¡Œ
            paragraphs.append(line)
    
    # ç”¨åŒæ¢è¡Œç¬¦è¿æ¥æ®µè½
    content = '\n\n'.join(paragraphs)
    
    # åº”ç”¨æ°´å°å¤„ç†
    content = apply_watermark_to_chapter(content)
    
    return content


def _get_status_file_path(book_id: str) -> str:
    """è·å–ä¸‹è½½çŠ¶æ€æ–‡ä»¶è·¯å¾„ï¼ˆä¿å­˜åœ¨ä¸´æ—¶ç›®å½•ï¼Œä¸æ±¡æŸ“å°è¯´ç›®å½•ï¼‰"""
    import tempfile
    import hashlib
    # ä½¿ç”¨ book_id çš„å“ˆå¸Œä½œä¸ºæ–‡ä»¶åï¼Œé¿å…å†²çª
    status_dir = os.path.join(tempfile.gettempdir(), 'fanqie_novel_downloader')
    os.makedirs(status_dir, exist_ok=True)
    filename = f".download_status_{book_id}.json"
    return os.path.join(status_dir, filename)


def load_status(book_id: str):
    """åŠ è½½ä¸‹è½½çŠ¶æ€ï¼ˆä»ä¸´æ—¶ç›®å½•è¯»å–ï¼‰"""
    status_file = _get_status_file_path(book_id)
    if os.path.exists(status_file):
        try:
            with open(status_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                if isinstance(data, list):
                    return set(data)
        except:
            pass
    return set()


def save_status(book_id: str, downloaded_ids):
    """ä¿å­˜ä¸‹è½½çŠ¶æ€ï¼ˆä¿å­˜åˆ°ä¸´æ—¶ç›®å½•ï¼‰"""
    status_file = _get_status_file_path(book_id)
    try:
        with open(status_file, 'w', encoding='utf-8') as f:
            json.dump(list(downloaded_ids), f, ensure_ascii=False, indent=2)
    except Exception as e:
        with print_lock:
            print(t("dl_save_status_fail", str(e)))


def clear_status(book_id: str):
    """æ¸…é™¤ä¸‹è½½çŠ¶æ€ï¼ˆä¸‹è½½å®Œæˆåè°ƒç”¨ï¼‰"""
    status_file = _get_status_file_path(book_id)
    try:
        if os.path.exists(status_file):
            os.remove(status_file)
    except:
        pass


def analyze_download_completeness(chapter_results: dict, expected_chapters: list = None, log_func=None) -> dict:
    """
    åˆ†æä¸‹è½½å®Œæ•´æ€§
    
    Args:
        chapter_results: å·²ä¸‹è½½çš„ç« èŠ‚ç»“æœ {index: {'title': ..., 'content': ...}}
        expected_chapters: æœŸæœ›çš„ç« èŠ‚åˆ—è¡¨ [{'id': ..., 'title': ..., 'index': ...}]
        log_func: æ—¥å¿—è¾“å‡ºå‡½æ•°
    
    Returns:
        åˆ†æç»“æœå­—å…¸:
        - total_expected: æœŸæœ›æ€»ç« èŠ‚æ•°
        - total_downloaded: å·²ä¸‹è½½ç« èŠ‚æ•°
        - missing_indices: ç¼ºå¤±çš„ç« èŠ‚ç´¢å¼•åˆ—è¡¨
        - order_correct: é¡ºåºæ˜¯å¦æ­£ç¡®
        - completeness_percent: å®Œæ•´åº¦ç™¾åˆ†æ¯”
    """
    def log(msg, progress=-1):
        if log_func:
            log_func(msg, progress)
        else:
            print(msg)
    
    result = {
        'total_expected': 0,
        'total_downloaded': len(chapter_results),
        'missing_indices': [],
        'order_correct': True,
        'completeness_percent': 100.0
    }
    
    if not chapter_results:
        log(t("dl_analyze_no_chapters"))
        result['completeness_percent'] = 0
        return result
    
    # è·å–å·²ä¸‹è½½çš„ç« èŠ‚ç´¢å¼•
    downloaded_indices = set(chapter_results.keys())
    
    # å¦‚æœæœ‰æœŸæœ›çš„ç« èŠ‚åˆ—è¡¨ï¼Œè¿›è¡Œå®Œæ•´æ€§æ¯”å¯¹
    if expected_chapters:
        expected_indices = set(ch['index'] for ch in expected_chapters)
        result['total_expected'] = len(expected_indices)
        
        # æŸ¥æ‰¾ç¼ºå¤±çš„ç« èŠ‚
        missing_indices = expected_indices - downloaded_indices
        result['missing_indices'] = sorted(list(missing_indices))
        
        if missing_indices:
            missing_count = len(missing_indices)
            log(t("dl_analyze_summary", len(expected_indices), len(downloaded_indices), missing_count))
            
            # æ˜¾ç¤ºéƒ¨åˆ†ç¼ºå¤±ç« èŠ‚ä¿¡æ¯
            if missing_count <= 10:
                missing_titles = []
                for ch in expected_chapters:
                    if ch['index'] in missing_indices:
                        missing_titles.append(f"{t('dl_chapter_title', ch['index']+1)}: {ch['title']}")
                log(t("dl_analyze_missing", ', '.join(missing_titles[:5])))
        else:
            log(t("dl_analyze_pass", len(expected_indices)))
    else:
        # æ²¡æœ‰æœŸæœ›åˆ—è¡¨ï¼Œä½¿ç”¨å·²ä¸‹è½½å†…å®¹åˆ†æ
        result['total_expected'] = len(chapter_results)
        
        # æ£€æŸ¥ç´¢å¼•æ˜¯å¦è¿ç»­
        sorted_indices = sorted(downloaded_indices)
        if sorted_indices:
            min_idx, max_idx = sorted_indices[0], sorted_indices[-1]
            expected_range = set(range(min_idx, max_idx + 1))
            missing_in_range = expected_range - downloaded_indices
            
            if missing_in_range:
                result['missing_indices'] = sorted(list(missing_in_range))
                log(t("dl_analyze_gap", sorted(missing_in_range)[:10]))
    
    # éªŒè¯ç« èŠ‚é¡ºåºï¼ˆæ£€æŸ¥æ ‡é¢˜ä¸­çš„ç« èŠ‚å·æ˜¯å¦é€’å¢ï¼‰
    sorted_results = sorted(chapter_results.items(), key=lambda x: x[0])
    order_issues = []
    
    for i in range(1, len(sorted_results)):
        prev_idx, prev_data = sorted_results[i-1]
        curr_idx, curr_data = sorted_results[i]
        
        # æ£€æŸ¥ç´¢å¼•æ˜¯å¦è¿ç»­
        if curr_idx != prev_idx + 1:
            order_issues.append({
                'type': 'gap',
                'from_index': prev_idx,
                'to_index': curr_idx,
                'gap': curr_idx - prev_idx - 1
            })
    
    if order_issues:
        result['order_correct'] = False
        total_gaps = sum(issue['gap'] for issue in order_issues)
        log(t("dl_analyze_order_fail", len(order_issues), total_gaps))
    else:
        log(t("dl_analyze_order_pass"))
    
    # è®¡ç®—å®Œæ•´åº¦
    if result['total_expected'] > 0:
        result['completeness_percent'] = (result['total_downloaded'] / result['total_expected']) * 100
    
    return result


def download_cover(cover_url, headers):
    """ä¸‹è½½å°é¢å›¾ç‰‡"""
    if not cover_url:
        return None, None, None
    
    try:
        response = requests.get(cover_url, headers=headers, timeout=15)
        if response.status_code != 200:
            return None, None, None
        
        content_type = response.headers.get('content-type', '')
        content_bytes = response.content
        
        if len(content_bytes) < 1000:
            return None, None, None
        
        if 'jpeg' in content_type or 'jpg' in content_type:
            file_ext, mime_type = '.jpg', 'image/jpeg'
        elif 'png' in content_type:
            file_ext, mime_type = '.png', 'image/png'
        elif 'webp' in content_type:
            file_ext, mime_type = '.webp', 'image/webp'
        else:
            file_ext, mime_type = '.jpg', 'image/jpeg'
        
        return content_bytes, file_ext, mime_type
        
    except Exception as e:
        with print_lock:
            print(t("dl_cover_fail", str(e)))
        return None, None, None


def create_epub(name, author_name, description, cover_url, chapters, save_path):
    """åˆ›å»ºEPUBæ–‡ä»¶"""
    book = epub.EpubBook()
    book.set_identifier(f'fanqie_{int(time.time())}')
    book.set_title(name)
    book.set_language('zh-CN')
    
    if author_name:
        book.add_author(author_name)
    
    if description:
        book.add_metadata('DC', 'description', description)
    
    if cover_url:
        try:
            cover_content, file_ext, mime_type = download_cover(cover_url, get_headers())
            if cover_content and file_ext and mime_type:
                book.set_cover(f'cover{file_ext}', cover_content)
        except Exception as e:
            with print_lock:
                print(t("dl_cover_add_fail", str(e)))
    
    spine_items = ['nav']
    toc_items = []
    
    # åˆ›å»ºä¹¦ç±ä¿¡æ¯é¡µ (ç®€ä»‹é¡µ)
    intro_html = f'<h1>{name}</h1>'
    if author_name:
        intro_html += f'<p><strong>ä½œè€…ï¼š</strong> {author_name}</p>'
    
    if description:
        intro_html += '<hr/>'
        intro_html += f'<h3>{t("dl_intro_title")}</h3>'
        # å¤„ç†ç®€ä»‹çš„æ¢è¡Œ
        desc_lines = description.split('\n')
        for line in desc_lines:
            if line.strip():
                intro_html += f'<p>{line.strip()}</p>'
                
    intro_chapter = epub.EpubHtml(title=t('dl_book_detail_title'), file_name='intro.xhtml', lang='zh-CN')
    intro_chapter.content = intro_html
    book.add_item(intro_chapter)
    
    # å°†ç®€ä»‹é¡µæ·»åŠ åˆ° spine å’Œ toc
    spine_items.append(intro_chapter)
    toc_items.append(intro_chapter)

    for idx, ch_data in enumerate(chapters):
        chapter_file = f'chapter_{idx + 1}.xhtml'
        title = ch_data.get('title', f'ç¬¬{idx + 1}ç« ')
        content = ch_data.get('content', '')
        
        # å°†æ¢è¡Œç¬¦è½¬æ¢ä¸ºHTMLæ®µè½æ ‡ç­¾
        paragraphs = content.split('\n\n') if content else []
        html_paragraphs = ''.join(f'<p>{p.strip()}</p>' for p in paragraphs if p.strip())
        
        chapter = epub.EpubHtml(
            title=title,
            file_name=chapter_file,
            lang='zh-CN'
        )
        chapter.content = f'<h1>{title}</h1><div>{html_paragraphs}</div>'
        
        book.add_item(chapter)
        spine_items.append(chapter)
        toc_items.append(chapter)
    
    book.toc = toc_items
    book.spine = spine_items
    
    book.add_item(epub.EpubNcx())
    book.add_item(epub.EpubNav())
    
    filename = re.sub(r'[\\/:*?"<>|]', '_', name)
    epub_path = os.path.join(save_path, f'{filename}.epub')
    epub.write_epub(epub_path, book)
    
    return epub_path


def create_txt(name, author_name, description, chapters, save_path):
    """åˆ›å»ºTXTæ–‡ä»¶"""
    filename = re.sub(r'[\\/:*?"<>|]', '_', name)
    txt_path = os.path.join(save_path, f'{filename}.txt')
    
    with open(txt_path, 'w', encoding='utf-8') as f:
        f.write(f"{name}\n")
        if author_name:
            f.write(f"{t('label_author')}{author_name}\n")
        if description:
            f.write(f"\n{t('dl_intro_title')}:\n{description}\n")
        f.write("\n" + "="*50 + "\n\n")
        
        for ch_data in chapters:
            title = ch_data.get('title', '')
            content = ch_data.get('content', '')
            f.write(f"\n{title}\n\n")
            f.write(f"{content}\n\n")
    
    return txt_path


def Run(book_id, save_path, file_formats='txt', start_chapter=None, end_chapter=None, selected_chapters=None, gui_callback=None):
    """è¿è¡Œä¸‹è½½
    
    Args:
        file_formats: æ–‡ä»¶æ ¼å¼ï¼Œå¯ä»¥æ˜¯å­—ç¬¦ä¸²('txt')æˆ–åˆ—è¡¨(['txt', 'epub'])
    """
    # å…¼å®¹æ—§æ¥å£ï¼šå¦‚æœæ˜¯å­—ç¬¦ä¸²åˆ™è½¬ä¸ºåˆ—è¡¨
    if isinstance(file_formats, str):
        file_formats = [file_formats]
    
    api = get_api_manager()
    if api is None:
        return False
    
    def log_message(message, progress=-1):
        if gui_callback and len(inspect.signature(gui_callback).parameters) > 1:
            gui_callback(progress, message)
        else:
            print(message)
    
    try:
        log_message(t("dl_fetching_info"), 5)
        book_detail = api.get_book_detail(book_id)
        if not book_detail:
            log_message(t("dl_fetch_info_fail"))
            return False
        
        name = book_detail.get("book_name", f"æœªçŸ¥å°è¯´_{book_id}")
        author_name = book_detail.get("author", t("dl_unknown_author"))
        description = book_detail.get("abstract", "")
        cover_url = book_detail.get("thumb_url", "")
        
        log_message(t("dl_book_info_log", name, author_name), 10)
        
        chapter_results = {}
        use_full_download = False
        
        # å…ˆè·å–ç« èŠ‚ç›®å½•ï¼ˆä¼˜å…ˆä½¿ç”¨ directory æ¥å£ï¼Œæ›´å¿«ä¸”æ ‡é¢˜ä¸æ•´æœ¬ä¸‹è½½ä¸€è‡´ï¼‰
        log_message("æ­£åœ¨è·å–ç« èŠ‚åˆ—è¡¨...", 15)
        chapters = []
        
        # ä¼˜å…ˆå°è¯• directory æ¥å£
        directory_data = api.get_directory(book_id)
        if directory_data:
            for idx, ch in enumerate(directory_data):
                item_id = ch.get("item_id")
                title = ch.get("title", f"ç¬¬{idx+1}ç« ")
                if item_id:
                    chapters.append({"id": str(item_id), "title": title, "index": idx})
        
        # é™çº§åˆ° book æ¥å£
        if not chapters:
            chapters_data = api.get_chapter_list(book_id)
            if chapters_data:
                if isinstance(chapters_data, dict):
                    all_item_ids = chapters_data.get("allItemIds", [])
                    chapter_list = chapters_data.get("chapterListWithVolume", [])
                    
                    if chapter_list:
                        idx = 0
                        for volume in chapter_list:
                            if isinstance(volume, list):
                                for ch in volume:
                                    if isinstance(ch, dict):
                                        item_id = ch.get("itemId") or ch.get("item_id")
                                        title = ch.get("title", f"ç¬¬{idx+1}ç« ")
                                        if item_id:
                                            chapters.append({"id": str(item_id), "title": title, "index": idx})
                                            idx += 1
                    else:
                        for idx, item_id in enumerate(all_item_ids):
                            chapters.append({"id": str(item_id), "title": f"ç¬¬{idx+1}ç« ", "index": idx})
                elif isinstance(chapters_data, list):
                    for idx, ch in enumerate(chapters_data):
                        item_id = ch.get("item_id") or ch.get("chapter_id")
                        title = ch.get("title", f"ç¬¬{idx+1}ç« ")
                        if item_id:
                            chapters.append({"id": str(item_id), "title": title, "index": idx})
        
        if not chapters:
            log_message(t("dl_fetch_list_fail"))
            return False
        
        total_chapters = len(chapters)
        log_message(t("dl_found_chapters", total_chapters), 20)
        
        # å°è¯•æé€Ÿä¸‹è½½æ¨¡å¼ (ä»…å½“æ²¡æœ‰æŒ‡å®šèŒƒå›´ä¸”æ²¡æœ‰é€‰æ‹©ç‰¹å®šç« èŠ‚æ—¶)
        if start_chapter is None and end_chapter is None and not selected_chapters:
            log_message(t("dl_try_speed_mode"), 25)
            full_text = api.get_full_content(book_id)
            if full_text:
                log_message(t("dl_speed_mode_success"), 30)
                # ä½¿ç”¨ç›®å½•æ ‡é¢˜æ¥åˆ†å‰²å†…å®¹
                chapters_parsed = parse_novel_text_with_catalog(full_text, chapters)
                
                if chapters_parsed and len(chapters_parsed) >= len(chapters) * 0.8:
                    # æˆåŠŸè§£æå‡ºè‡³å°‘80%çš„ç« èŠ‚
                    log_message(t("dl_speed_mode_parsed", len(chapters_parsed)), 50)
                    with tqdm(total=len(chapters_parsed), desc=t("dl_processing_chapters"), disable=gui_callback is not None) as pbar:
                        for ch in chapters_parsed:
                            processed = process_chapter_content(ch['content'])
                            chapter_results[ch['index']] = {
                                'title': ch['title'],
                                'content': processed
                            }
                            if pbar: pbar.update(1)
                    
                    use_full_download = True
                    log_message(t("dl_process_complete"), 80)
                else:
                    parsed_count = len(chapters_parsed) if chapters_parsed else 0
                    log_message(f"æ€¥é€Ÿæ¨¡å¼è§£æä¸å®Œæ•´ ({parsed_count}/{total_chapters})ï¼Œåˆ‡æ¢åˆ°æ™®é€šæ¨¡å¼")
            else:
                log_message(t("dl_speed_mode_fail"))

        # å¦‚æœæ²¡æœ‰ä½¿ç”¨æé€Ÿæ¨¡å¼ï¼Œåˆ™èµ°æ™®é€šæ¨¡å¼
        if not use_full_download:
            
            if not chapters:
                log_message(t("dl_no_chapters_found"))
                return False
            
            total_chapters = len(chapters)
            log_message(t("dl_found_chapters", total_chapters), 20)
            
            if start_chapter is not None or end_chapter is not None:
                start_idx = (start_chapter - 1) if start_chapter else 0
                end_idx = end_chapter if end_chapter else total_chapters
                chapters = chapters[start_idx:end_idx]
                log_message(t("dl_range_log", start_idx+1, end_idx))
            
            if selected_chapters:
                try:
                    selected_indices = set(int(x) for x in selected_chapters)
                    chapters = [ch for ch in chapters if ch['index'] in selected_indices]
                    log_message(t("dl_selected_log", len(chapters)))
                except Exception as e:
                    log_message(t("dl_filter_error", e))
            
            downloaded_ids = load_status(book_id)
            chapters_to_download = [ch for ch in chapters if ch["id"] not in downloaded_ids]
            
            if not chapters_to_download:
                log_message(t("dl_all_downloaded"))
            else:
                log_message(t("dl_start_download_log", len(chapters_to_download)), 25)
            
            completed = 0
            total_tasks = len(chapters_to_download)
            
            with tqdm(total=total_tasks, desc=t("dl_progress_desc"), disable=gui_callback is not None) as pbar:
                with ThreadPoolExecutor(max_workers=CONFIG.get("max_workers", 5)) as executor:
                    future_to_chapter = {
                        executor.submit(api.get_chapter_content, ch["id"]): ch
                        for ch in chapters_to_download
                    }
                    
                    for future in as_completed(future_to_chapter):
                        ch = future_to_chapter[future]
                        try:
                            data = future.result()
                            if data and data.get('content'):
                                processed = process_chapter_content(data.get('content', ''))
                                chapter_results[ch['index']] = {
                                    'title': ch['title'],
                                    'content': processed
                                }
                                downloaded_ids.add(ch['id'])
                                completed += 1
                                if pbar:
                                    pbar.update(1)
                                if gui_callback:
                                    progress = int((completed / total_tasks) * 60) + 25
                                    gui_callback(progress, t("dl_progress_log", completed, total_tasks))
                        except Exception:
                            pass
            
            save_status(book_id, downloaded_ids)
        
        # ==================== ä¸‹è½½å®Œæ•´æ€§åˆ†æ ====================
        if gui_callback:
            gui_callback(85, t("dl_analyzing_completeness"))
        else:
            log_message(t("dl_analyzing_completeness"), 85)
        
        # åˆ†æç»“æœ
        analysis_result = analyze_download_completeness(
            chapter_results, 
            chapters if not use_full_download else None,
            log_message
        )
        
        # å¦‚æœæœ‰ç¼ºå¤±ç« èŠ‚ï¼Œå°è¯•è¡¥å……ä¸‹è½½
        if analysis_result['missing_indices'] and not use_full_download:
            missing_count = len(analysis_result['missing_indices'])
            log_message(t("dl_missing_retry", missing_count), 87)
            
            # è·å–ç¼ºå¤±ç« èŠ‚çš„ä¿¡æ¯
            missing_chapters = [ch for ch in chapters if ch['index'] in analysis_result['missing_indices']]
            
            # è¡¥å……ä¸‹è½½ç¼ºå¤±ç« èŠ‚ï¼ˆæœ€å¤šé‡è¯•3æ¬¡ï¼‰
            for retry in range(3):
                if not missing_chapters:
                    break
                    
                log_message(t("dl_retry_log", retry + 1, len(missing_chapters)), 88)
                still_missing = []
                
                for ch in missing_chapters:
                    try:
                        data = api.get_chapter_content(ch["id"])
                        if data and data.get('content'):
                            processed = process_chapter_content(data.get('content', ''))
                            chapter_results[ch['index']] = {
                                'title': ch['title'],
                                'content': processed
                            }
                            downloaded_ids.add(ch['id'])
                        else:
                            still_missing.append(ch)
                    except Exception:
                        still_missing.append(ch)
                    time.sleep(0.5)  # é¿å…è¯·æ±‚è¿‡å¿«
                
                missing_chapters = still_missing
                if not missing_chapters:
                    log_message(t("dl_retry_success"), 90)
                    break
            
            # æ›´æ–°çŠ¶æ€
            save_status(book_id, downloaded_ids)
            
            # æœ€ç»ˆæ£€æŸ¥
            if missing_chapters:
                missing_indices = [ch['index'] + 1 for ch in missing_chapters]
                log_message(t("dl_retry_fail", len(missing_chapters), missing_indices[:10]), 90)
        
        # éªŒè¯ç« èŠ‚é¡ºåº
        if gui_callback:
            gui_callback(92, t("dl_verifying_order"))
        
        sorted_indices = sorted(chapter_results.keys())
        order_issues = []
        for i, idx in enumerate(sorted_indices):
            if i > 0 and idx != sorted_indices[i-1] + 1:
                order_issues.append((sorted_indices[i-1], idx))
        
        if order_issues:
            log_message(f"âš ï¸ æ£€æµ‹åˆ°ç« èŠ‚åºå·ä¸è¿ç»­: {order_issues[:5]}{'...' if len(order_issues) > 5 else ''}", 93)
        else:
            log_message("âœ… ç« èŠ‚é¡ºåºéªŒè¯é€šè¿‡", 93)
        
        # æœ€ç»ˆç»Ÿè®¡
        total_expected = len(chapters) if not use_full_download else len(chapter_results)
        total_downloaded = len(chapter_results)
        completeness = (total_downloaded / total_expected * 100) if total_expected > 0 else 100
        
        log_message(f"ğŸ“Š ä¸‹è½½ç»Ÿè®¡: {total_downloaded}/{total_expected} ç«  ({completeness:.1f}%)", 95)
        
        if gui_callback:
            gui_callback(95, "æ­£åœ¨ç”Ÿæˆæ–‡ä»¶...")
        
        sorted_chapters = [chapter_results[idx] for idx in sorted(chapter_results.keys()) if idx in chapter_results]

        
        # æ ¹æ®é€‰æ‹©çš„æ ¼å¼ç”Ÿæˆæ–‡ä»¶
        output_files = []
        for fmt in file_formats:
            if fmt == 'epub':
                output_files.append(create_epub(name, author_name, description, cover_url, sorted_chapters, save_path))
            else:
                output_files.append(create_txt(name, author_name, description, sorted_chapters, save_path))
        output_file = ', '.join(output_files)
        
        # ä¸‹è½½å®Œæˆåæ¸…é™¤ä¸´æ—¶çŠ¶æ€æ–‡ä»¶
        clear_status(book_id)
        
        # æœ€ç»ˆç»“æœ
        if completeness >= 100:
            log_message(f"âœ… ä¸‹è½½å®Œæˆ! æ–‡ä»¶: {output_file}", 100)
        else:
            log_message(f"âš ï¸ ä¸‹è½½å®Œæˆ(éƒ¨åˆ†ç« èŠ‚ç¼ºå¤±)! æ–‡ä»¶: {output_file}", 100)
        
        return True
        
    except Exception as e:
        log_message(f"ä¸‹è½½å¤±è´¥: {str(e)}")
        return False


class NovelDownloader:
    """å°è¯´ä¸‹è½½å™¨ç±»"""
    
    def __init__(self):
        self.is_cancelled = False
        self.current_progress_callback = None
        self.gui_verification_callback = None
    
    def cancel_download(self):
        """å–æ¶ˆä¸‹è½½"""
        self.is_cancelled = True
    
    def run_download(self, book_id, save_path, file_formats='txt', start_chapter=None, end_chapter=None, selected_chapters=None, gui_callback=None):
        """è¿è¡Œä¸‹è½½"""
        try:
            if gui_callback:
                self.gui_verification_callback = gui_callback
            
            return Run(book_id, save_path, file_formats, start_chapter, end_chapter, selected_chapters, gui_callback)
        except Exception as e:
            print(f"ä¸‹è½½å¤±è´¥: {str(e)}")
            return False
    
    def search_novels(self, keyword, offset=0):
        """æœç´¢å°è¯´"""
        try:
            api = get_api_manager()
            if api is None:
                return None
            
            search_results = api.search_books(keyword, offset)
            if search_results and search_results.get("data"):
                return search_results["data"]
            return None
        except Exception as e:
            with print_lock:
                print(t("dl_search_fail", str(e)))
            return None


downloader_instance = NovelDownloader()


class BatchDownloader:
    """æ‰¹é‡ä¸‹è½½å™¨"""
    
    def __init__(self):
        self.is_cancelled = False
        self.results = []  # ä¸‹è½½ç»“æœåˆ—è¡¨
        self.current_index = 0
        self.total_count = 0
    
    def cancel(self):
        """å–æ¶ˆæ‰¹é‡ä¸‹è½½"""
        self.is_cancelled = True
    
    def reset(self):
        """é‡ç½®çŠ¶æ€"""
        self.is_cancelled = False
        self.results = []
        self.current_index = 0
        self.total_count = 0
    
    def run_batch(self, book_ids: list, save_path: str, file_format: str = 'txt', 
                  progress_callback=None, delay_between_books: float = 2.0):
        """
        æ‰¹é‡ä¸‹è½½å¤šæœ¬ä¹¦ç±
        
        Args:
            book_ids: ä¹¦ç±IDåˆ—è¡¨
            save_path: ä¿å­˜è·¯å¾„
            file_format: æ–‡ä»¶æ ¼å¼ ('txt' æˆ– 'epub')
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•° (current, total, book_name, status, message)
            delay_between_books: æ¯æœ¬ä¹¦ä¹‹é—´çš„å»¶è¿Ÿï¼ˆç§’ï¼‰
        
        Returns:
            dict: æ‰¹é‡ä¸‹è½½ç»“æœ
        """
        self.reset()
        self.total_count = len(book_ids)
        
        if not book_ids:
            return {'success': False, 'message': t('dl_batch_no_books'), 'results': []}
        
        api = get_api_manager()
        if api is None:
            return {'success': False, 'message': t('dl_batch_api_fail'), 'results': []}
        
        def log(msg):
            print(msg)
        
        log(t("dl_batch_start", self.total_count))
        log("=" * 50)
        
        for idx, book_id in enumerate(book_ids):
            if self.is_cancelled:
                log(t("dl_batch_cancelled"))
                break
            
            self.current_index = idx + 1
            book_id = str(book_id).strip()
            
            # è·å–ä¹¦ç±ä¿¡æ¯
            book_name = f"ä¹¦ç±_{book_id}"
            try:
                book_detail = api.get_book_detail(book_id)
                if book_detail:
                    book_name = book_detail.get('book_name', book_name)
            except:
                pass
            
            log("\n" + t("dl_batch_downloading", self.current_index, self.total_count, book_name))
            
            if progress_callback:
                progress_callback(self.current_index, self.total_count, book_name, 'downloading', t("dl_batch_progress", self.current_index))
            
            # æ‰§è¡Œä¸‹è½½
            result = {
                'book_id': book_id,
                'book_name': book_name,
                'success': False,
                'message': ''
            }
            
            try:
                # åˆ›å»ºå•æœ¬ä¹¦çš„è¿›åº¦å›è°ƒ
                def single_book_callback(progress, message):
                    if progress_callback:
                        overall_progress = ((self.current_index - 1) / self.total_count * 100) + (progress / self.total_count)
                        progress_callback(self.current_index, self.total_count, book_name, 'downloading', message)
                
                success = Run(book_id, save_path, file_format, gui_callback=single_book_callback)
                
                if success:
                    result['success'] = True
                    result['message'] = 'ä¸‹è½½æˆåŠŸ'
                    log(t("dl_batch_success", book_name))
                else:
                    result['message'] = 'ä¸‹è½½å¤±è´¥'
                    log(t("dl_batch_fail", book_name))
                    
            except Exception as e:
                result['message'] = str(e)
                log(t("dl_batch_exception", book_name, str(e)))
            
            self.results.append(result)
            
            if progress_callback:
                status = 'success' if result['success'] else 'failed'
                progress_callback(self.current_index, self.total_count, book_name, status, result['message'])
            
            # å»¶è¿Ÿï¼Œé¿å…è¯·æ±‚è¿‡å¿«
            if idx < len(book_ids) - 1 and not self.is_cancelled:
                time.sleep(delay_between_books)
        
        # ç»Ÿè®¡ç»“æœ
        success_count = sum(1 for r in self.results if r['success'])
        failed_count = len(self.results) - success_count
        
        log("\n" + "=" * 50)
        log(t("dl_batch_summary"))
        log(t("dl_batch_stats_success", success_count))
        log(t("dl_batch_stats_fail", failed_count))
        log(t("dl_batch_stats_total", len(self.results)))
        
        if failed_count > 0:
            log("\n" + t("dl_batch_fail_list"))
            for r in self.results:
                if not r['success']:
                    log(f"   - ã€Š{r['book_name']}ã€‹: {r['message']}")
        
        return {
            'success': failed_count == 0,
            'message': t("dl_batch_complete", success_count, len(self.results)),
            'total': len(self.results),
            'success_count': success_count,
            'failed_count': failed_count,
            'results': self.results
        }


batch_downloader = BatchDownloader()


def signal_handler(sig, frame):
    """ä¿¡å·å¤„ç†"""
    print('\næ­£åœ¨å–æ¶ˆä¸‹è½½...')
    downloader_instance.cancel_download()
    batch_downloader.cancel()
    sys.exit(0)


if __name__ == "__main__":
    try:
        signal.signal(signal.SIGINT, signal_handler)
    except ValueError:
        pass
    
    print("ç•ªèŒ„å°è¯´ä¸‹è½½å™¨")
    print("="*50)
    print("1. å•æœ¬ä¸‹è½½")
    print("2. æ‰¹é‡ä¸‹è½½")
    mode = input("é€‰æ‹©æ¨¡å¼ (1/2, é»˜è®¤: 1): ").strip() or "1"
    
    save_path = input("è¯·è¾“å…¥ä¿å­˜è·¯å¾„(é»˜è®¤: ./novels): ").strip() or "./novels"
    file_format = input("é€‰æ‹©æ ¼å¼ (txt/epub, é»˜è®¤: txt): ").strip() or "txt"
    os.makedirs(save_path, exist_ok=True)
    
    if mode == "2":
        # æ‰¹é‡ä¸‹è½½æ¨¡å¼
        print("\nè¯·è¾“å…¥ä¹¦ç±IDåˆ—è¡¨ï¼ˆæ¯è¡Œä¸€ä¸ªï¼Œè¾“å…¥ç©ºè¡Œç»“æŸï¼‰:")
        book_ids = []
        while True:
            line = input().strip()
            if not line:
                break
            # æ”¯æŒé€—å·/ç©ºæ ¼/æ¢è¡Œåˆ†éš”
            for bid in re.split(r'[,\s]+', line):
                bid = bid.strip()
                if bid:
                    book_ids.append(bid)
        
        if book_ids:
            print(f"\nå…± {len(book_ids)} æœ¬ä¹¦ç±å¾…ä¸‹è½½")
            result = batch_downloader.run_batch(book_ids, save_path, file_format)
            print(f"\næ‰¹é‡ä¸‹è½½ç»“æŸ: {result['message']}")
        else:
            print("æ²¡æœ‰è¾“å…¥ä¹¦ç±ID")
    else:
        # å•æœ¬ä¸‹è½½æ¨¡å¼
        book_id = input("è¯·è¾“å…¥ä¹¦ç±ID: ").strip()
        success = Run(book_id, save_path, file_format)
        if success:
            print("ä¸‹è½½å®Œæˆ!")
        else:
            print("ä¸‹è½½å¤±è´¥!")